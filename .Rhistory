rm(list = ls())
setwd("/Users/cinyee/Desktop/Stevens/2020spring/513/HW")
data <- read.csv("breast-cancer-wisconsin.data.csv")
data[data == "?"] <- NA
data <- na.omit(data)
data <- data[ , -1]
view(data)
rm(list = ls())
rm(list = ls())
data <- read.csv("breast-cancer-wisconsin.data.csv")
data[data == "?"] <- NA
data <- na.omit(data)
data <- data[ , -1]
view(data)
data <- read.csv("breast-cancer-wisconsin.data.csv")
data[data == "?"] <- NA
data <- na.omit(data)
data <- data[ , -1]
View(data)
rm(list = ls())
setwd("/Users/cinyee/Desktop/Stevens/2020spring/513/HW")
data <- read.csv("breast-cancer-wisconsin.data.csv")
View(data)
# Use the knn methodology (k=3,5 and 10) to develop a classification models for the Diagnosis.
# Make sure your categories are represented by the “factor” data type in R
# and delete the rows with missing value.
data[data == "?"] <- NA
data <- na.omit(data)
data <- data[ , -1]
data$F6 <- as.integer(as.character(data$F6))
data$Class<-as.factor(data$Class)
levels(data$Class)<-c("benign","malignant")
View(data)
setwd("/Users/cinyee/Desktop/Stevens/2020spring/513/HW")
data <- read.csv("breast-cancer-wisconsin.data.csv")
View(data)
rm(list = ls())
setwd("/Users/cinyee/Desktop/Stevens/2020spring/513/DataMiningHW")
data <- read.csv("breast-cancer-wisconsin.data.csv")
data[data == "?"] <- NA
data <- na.omit(data)
data <- data[ , -1]
View(data)
data$Class <- as.factor(data$Class)
levels(data$Class) <- c("benign","malignant")
View(data)
summary(data)
prop.table(table(data$Class))
# Use 30% test 70% training data.
selected_index <- sample(nrow(data), as.integer(nrow(data) * 0.7))
training_data <- data[selected_index, ]
test_data <- data[-selected_index, ]
# Naïve Bayeswith training and test
model <- naiveBayes(Class~., data = training_data)
predict_class <- predict(model,newdata = test_data)
# Confusion matrix for finding accuracy
conf_matrix <- table(predict_class, test_data$Class)
confusionMatrix(conf_matrix)
# Fitting the Naive Bayes model with all data
nBayes_class <- naiveBayes(Class~., data = data)
# Print the model summary
nBayes_class
# Prediction on the dataset
category_class <- predict(nBayes_class, data)
table(NBayes = category_class, Diagnosis = data$Class)
NB_wrong <- sum(category_class != data$Class)
NB_error_rate <- NB_wrong / length(category_class)
library(e1071)
library(caret)
# Naïve Bayeswith training and test
model <- naiveBayes(Class~., data = training_data)
predict_class <- predict(model,newdata = test_data)
# Confusion matrix for finding accuracy
conf_matrix <- table(predict_class, test_data$Class)
confusionMatrix(conf_matrix)
# Fitting the Naive Bayes model with all data
nBayes_class <- naiveBayes(Class~., data = data)
# Print the model summary
nBayes_class
# Prediction on the dataset
category_class <- predict(nBayes_class, data)
table(NBayes = category_class, Diagnosis = data$Class)
NB_wrong <- sum(category_class != data$Class)
NB_error_rate <- NB_wrong / length(category_class)
# Prediction on the dataset
category_class <- predict(nBayes_class, data)
table(NBayes = category_class, Diagnosis = data$Class)
NB_wrong <- sum(category_class != data$Class)
NB_error_rate <- NB_wrong / length(category_class)
# Prediction on the dataset
category_class <- predict(nBayes_class, data)
table(NBayes = category_class, Diagnosis = data$Class)
NB_wrong <- sum(category_class != data$Class)
NB_error_rate <- NB_wrong / length(category_class)
# Prediction on the dataset
category_class <- predict(nBayes_class, data)
table(NBayes = category_class, Diagnosis = data$Class)
NB_wrong <- sum(category_class != data$Class)
NB_error_rate <- NB_wrong / length(category_class)
rm(list = ls())
setwd("/Users/cinyee/Desktop/Stevens/2020spring/513/DataMiningHW")
data <- read.csv("breast-cancer-wisconsin.data.csv")
# Important: make sure your categories are represented by the “factor” data type in R
# and DO NOT replace the missing values.
# Change Class to factor
data$Class <- factor(data$Class, levels = c(2,4))
summary(data)
#training and tests
set.seed(111)
index<-sort(sample(nrow(data),round(.30*nrow(data))))
training<-data[-index,]
test<-data[index,]
#decision tree
tree=rpart(Class~.,data=training,method="class")
rpart.plot(tree, extra = 104, nn = TRUE)
fancyRpartPlot(tree)
install
library(rattle)
library(RColorBrewer)
library(rpart)
library(rpart.plot)
# Training and tests
set.seed(111)
index<-sort(sample(nrow(data),round(.30*nrow(data))))
training<-data[-index,]
test<-data[index,]
# Decision tree
tree=rpart(Class~.,data=training,method="class")
rpart.plot(tree, extra = 104, nn = TRUE)
fancyRpartPlot(tree)
library(rattle)
library(RColorBrewer)
library(rpart)
library(rpart.plot)
# Training and tests
set.seed(111)
index<-sort(sample(nrow(data),round(.30*nrow(data))))
training<-data[-index,]
test<-data[index,]
# Decision tree
tree=rpart(Class~.,data=training,method="class")
rpart.plot(tree, extra = 104, nn = TRUE)
fancyRpartPlot(tree)
library(RColorBrewer)
library(rpart)
# Training and tests
set.seed(111)
index<-sort(sample(nrow(data),round(.30*nrow(data))))
training<-data[-index,]
test<-data[index,]
# Decision tree
tree=rpart(Class~.,data=training,method="class")
rpart.plot(tree, extra = 104, nn = TRUE)
fancyRpartPlot(tree)
liabrary(rpart.plot)
library(rpart)
library(rpart.plot)
? rpart.plot
??rpart.plot
library(RColorBrewer)
library(rpart)
# Training and tests
set.seed(111)
index <- sort(sample(nrow(data), round(.30 * nrow(data))))
training <- data[-index, ]
test <- data[index, ]
tree = rpart(Class~., data = training, method = "class")
rpart.plot(tree, extra = 104, nn = TRUE)
?plot
rm(list = ls())
file <- file.choose()
bc <-  read.csv(file,
na.strings = "/Users/cinyee/Desktop/Stevens/2020spring/513/DataMiningHW/breast-cancer-wisconsin.data.csv",
colClasses=c("Sample"="character",
"F1"="factor","F2"="factor","F3"="factor",
"F4"="factor","F5"="factor","F6"="factor",
"F7"="factor","F8"="factor","F9"="factor",
"Class"="factor"))
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)
install.packages("rpart")
install.packages("rpart.plot")
install.packages("rpart.plot")
install.packages("RColorBrewer")
install.packages("RColorBrewer")
install.packages("rpart")
install.packages("rpart")
index<-sort(sample(nrow(bc),round(.30*nrow(bc ))))
training<-bc[-index,]
test<-bc[index,]
?rpart()
CART_class<-rpart( Class~.,data=training[,-1])
rpart.plot(CART_class)
CART_predict2<-predict(CART_class,test, type="class")
df<-as.data.frame(cbind(test,CART_predict2))
table(Actual=test[,"Class"],CART=CART_predict2)
CART_wrong<-sum(test[,"Class"]!=CART_predict2)
error_rate=CART_wrong/length(test$Class)
dev.off()
install.packages("rattle")
?rpart()
CART_class<-rpart( Class~.,data=training[,-1])
rpart.plot(CART_class)
CART_predict2<-predict(CART_class,test, type="class")
df<-as.data.frame(cbind(test,CART_predict2))
table(Actual=test[,"Class"],CART=CART_predict2)
CART_wrong<-sum(test[,"Class"]!=CART_predict2)
error_rate=CART_wrong/length(test$Class)
dev.off()
#install.packages("rpart")
#install.packages("rpart.plot")     # Enhanced tree plots
#install.packages("rattle")         # Fancy tree plot
#install.packages("RColorBrewer")   # colors needed for rattle
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
#dsn2<-data.frame(lapply(dsn[,-1],as.factor))
index<-sort(sample(nrow(bc),round(.30*nrow(bc ))))
training<-bc[-index,]
test<-bc[index,]
?rpart()
#Grow the tree
CART_class<-rpart( Class~.,data=training[,-1])
rpart.plot(CART_class)
CART_predict2<-predict(CART_class,test, type="class")
df<-as.data.frame(cbind(test,CART_predict2))
table(Actual=test[,"Class"],CART=CART_predict2)
CART_wrong<-sum(test[,"Class"]!=CART_predict2)
error_rate=CART_wrong/length(test$Class)
dev.off()
#install.packages("rpart")
#install.packages("rpart.plot")
#install.packages("rattle")
#install.packages("RColorBrewer")
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
index <- sort(sample(nrow(data), round(.30 * nrow(data))))
training <- data[-index, ]
test <- data[index, ]
?rpart()
#Grow the tree
CART_class <- rpart(Class~., data = training[ ,-1])
rpart.plot(CART_class)
CART_predict2 <- predict(CART_class, test, type = "class")
df <- as.data.frame(cbind(test, CART_predict2))
table(Actual = test[ , "Class"], CART = CART_predict2)
CART_wrong <- sum(test[ , "Class"] != CART_predict2)
error_rate = CART_wrong / length(test$Class)
dev.off()
rm(list = ls())
# Important: make sure your categories are represented by the “factor” data type in R
# and DO NOT replace the missing values.
file <- file.choose()
data <-  read.csv(file,
na.strings = "/Users/cinyee/Desktop/Stevens/2020spring/513/DataMiningHW/breast-cancer-wisconsin.data.csv",
colClasses=c("Sample"="character",
"F1"="factor","F2"="factor","F3"="factor",
"F4"="factor","F5"="factor","F6"="factor",
"F7"="factor","F8"="factor","F9"="factor",
"Class"="factor"))
#install.packages("rpart")
#install.packages("rpart.plot")
#install.packages("rattle")
#install.packages("RColorBrewer")
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
index <- sort(sample(nrow(data), round(.30 * nrow(data))))
training <- data[-index, ]
test <- data[index, ]
?rpart()
#Grow the tree
CART_class <- rpart(Class~., data = training[ ,-1])
rpart.plot(CART_class)
CART_predict2 <- predict(CART_class, test, type = "class")
df <- as.data.frame(cbind(test, CART_predict2))
table(Actual = test[ , "Class"], CART = CART_predict2)
CART_wrong <- sum(test[ , "Class"] != CART_predict2)
error_rate = CART_wrong / length(test$Class)
dev.off()
